{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "b06072eb-fd2a-43e1-a702-67ea305d63db",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from datasets import load_metric, load_dataset, load_from_disk\n",
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "5fd5c701-e8a7-41d9-8b08-629b43101ad3",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = load_from_disk('./data/train_dataset_lv1')\n",
    "valid_dataset = load_from_disk('./data/valid_dataset_lv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "861f71b9-8980-4173-9674-431edd014f88",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"microsoft/graphcodebert-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(MODEL)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "4528f711-89f7-481a-bdb5-13c55ebedab1",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "_metric = load_metric(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "5c3a4b33-874d-438e-974b-c3736fcfc259",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def metric_fn(p):\n",
    "    preds, labels = p\n",
    "    output =  _metric.compute(references=labels, predictions=np.argmax(preds, axis=-1))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "4514262a-bedb-4e3a-a3e8-9697e07999f5",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='./models/',\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    disable_tqdm = False,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    save_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=1e-5,\n",
    "    optim='adamw_torch',\n",
    "    # metric_for_best_model= \"f1\",\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=_collator,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics= metric_fn,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "4e659920-e286-4cfa-af72-6dc46f766183",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from knockknock import discord_sender\n",
    "\n",
    "webhook_url='https://discord.com/api/webhooks/981021972697858078/cKpZXsyxyFGptLsMiFfWdEbjwavkO0qgkgWGW3fyYeBxMkJFebDq9U5M4vgDibgM3Ew6'\n",
    "\n",
    "@discord_sender(webhook_url=webhook_url)\n",
    "def do_train():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "219c0af9-96d3-4a56-b494-d478cd7bb144",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 300000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 28125\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7285' max='28125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7285/28125 4:04:13 < 11:38:50, 0.50 it/s, Epoch 0.78/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.214068</td>\n",
       "      <td>0.917900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.125277</td>\n",
       "      <td>0.955067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.104267</td>\n",
       "      <td>0.964733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.090524</td>\n",
       "      <td>0.967833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.084862</td>\n",
       "      <td>0.973833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.116609</td>\n",
       "      <td>0.966233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.167759</td>\n",
       "      <td>0.952833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.072490</td>\n",
       "      <td>0.978967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.087920</td>\n",
       "      <td>0.976500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.079119</td>\n",
       "      <td>0.979367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.063753</td>\n",
       "      <td>0.981767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.071706</td>\n",
       "      <td>0.977267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.070533</td>\n",
       "      <td>0.981600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.058312</td>\n",
       "      <td>0.983100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-500\n",
      "Configuration saved in ./models/checkpoint-500/config.json\n",
      "Model weights saved in ./models/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-1000\n",
      "Configuration saved in ./models/checkpoint-1000/config.json\n",
      "Model weights saved in ./models/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1000/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-1500\n",
      "Configuration saved in ./models/checkpoint-1500/config.json\n",
      "Model weights saved in ./models/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-1500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-2000\n",
      "Configuration saved in ./models/checkpoint-2000/config.json\n",
      "Model weights saved in ./models/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2000/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-2500\n",
      "Configuration saved in ./models/checkpoint-2500/config.json\n",
      "Model weights saved in ./models/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-2500/special_tokens_map.json\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-3000\n",
      "Configuration saved in ./models/checkpoint-3000/config.json\n",
      "Model weights saved in ./models/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-3500\n",
      "Configuration saved in ./models/checkpoint-3500/config.json\n",
      "Model weights saved in ./models/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-4000\n",
      "Configuration saved in ./models/checkpoint-4000/config.json\n",
      "Model weights saved in ./models/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-1500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-4500\n",
      "Configuration saved in ./models/checkpoint-4500/config.json\n",
      "Model weights saved in ./models/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-5000\n",
      "Configuration saved in ./models/checkpoint-5000/config.json\n",
      "Model weights saved in ./models/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-2500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-5500\n",
      "Configuration saved in ./models/checkpoint-5500/config.json\n",
      "Model weights saved in ./models/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-6000\n",
      "Configuration saved in ./models/checkpoint-6000/config.json\n",
      "Model weights saved in ./models/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-3500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-6500\n",
      "Configuration saved in ./models/checkpoint-6500/config.json\n",
      "Model weights saved in ./models/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./models/checkpoint-7000\n",
      "Configuration saved in ./models/checkpoint-7000/config.json\n",
      "Model weights saved in ./models/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/checkpoint-4500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "do_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
