{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff8abf3-01ef-4205-bb88-a962eaab0b84",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "eecb0ba7-66a1-4bb3-b3ea-79167db1b4f5",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "# CodeSimilarity file using graphcodebert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74e19f-cf0d-4727-89cd-52028eb9b507",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "36234d4b-62bd-41e5-a793-b0a9a8c8de5d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Import module and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b5b915-b110-4a78-ab93-00cb52d81ec9",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "c0b65652-832a-4430-8a84-fee0fd018537",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from datasets import load_metric, load_dataset, load_from_disk\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86211a78-753a-4665-9b3a-84ced571beb0",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "5c720bc1-6022-46b2-a53a-96367cdefa43",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "### Load Dataset and device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3b481e-09e9-4d9c-b604-8358963c16c3",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "bd126b4d-4315-4c4c-ad58-f270f083a3e2",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = load_from_disk('../data/train_dataset_lv1')\n",
    "valid_dataset = load_from_disk('../data/valid_dataset_lv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4d051b-360e-4dad-aed4-b7d40b088120",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "03b8f019-2c44-4158-93cc-81ee06e7341a",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/piai/.jupyter/lab/workspaces/code_clone_detection/notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a0b1b0-23bf-453e-8ac0-6ca582731c46",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "ba197b2d-a905-41e8-b1d2-a9631baf8256",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "MODEL = \"/home/piai/.jupyter/lab/workspaces/code_clone_detection/notebooks/models/best_models\"\n",
    "MODEL2 = \"/home/piai/.jupyter/lab/workspaces/code_clone_detection/notebooks/models/1/checkpoint-19000\"\n",
    "MODEL3 = \"/home/piai/.jupyter/lab/workspaces/code_clone_detection/notebooks/models/fold3/checkpoint-1500\"\n",
    "MODEL4 = \"/home/piai/.jupyter/lab/workspaces/code_clone_detection/notebooks/models/fold4/checkpoint-1000\"\n",
    "MODEL5 = \"/home/piai/.jupyter/lab/workspaces/code_clone_detection/notebooks/models/fold4/checkpoint-2500\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LEN = 512\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.to(device)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(MODEL2)\n",
    "model2.to(device)\n",
    "model3 = AutoModelForSequenceClassification.from_pretrained(MODEL3)\n",
    "model3.to(device)\n",
    "model4 = AutoModelForSequenceClassification.from_pretrained(MODEL4)\n",
    "model4.to(device)\n",
    "model5 = AutoModelForSequenceClassification.from_pretrained(MODEL5)\n",
    "model5.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3b7fcc-3b92-490b-a7a8-8ec19908117c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "a5d0fef9-0402-4f13-86af-9f03ca1f8ec8",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "_metric = load_metric(\"glue\", \"sst2\")\n",
    "\n",
    "def example_fn(examples):\n",
    "    outputs = tokenizer(examples['code1'], examples['code2'], padding=True, max_length=MAX_LEN,truncation=True)\n",
    "    if 'similar' in examples:\n",
    "        outputs[\"labels\"] = examples[\"similar\"]\n",
    "    return outputs\n",
    "\n",
    "def metric_fn(p):\n",
    "    preds, labels = p\n",
    "    output =  _metric.compute(references=labels, predictions=np.argmax(preds, axis=-1))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e78624-5b10-42a0-969b-26ec9a24e101",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "47475d61-7fdd-49ac-b950-a561a2f00e31",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2bf9425-5b44-4f89-8862-af81d2a50f5d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": "e3418630-52dc-4bce-91fd-c62d9f11a216",
     "headerColor": "inherit",
     "id": "d4c35cf8-1be8-4618-8d4d-947fb146585a",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from knockknock import discord_sender\n",
    "\n",
    "webhook_url='https://discord.com/api/webhooks/982252843270561912/N-lIX9ZEyAnlTJpYn-2Z7IwczmyKbqmZOM-g_fh0XrVsHiWUfj1fknlaA33aGy9JSwwh'\n",
    "\n",
    "@discord_sender(webhook_url=webhook_url)\n",
    "def do_train():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e01bd6-c5de-4fe0-a727-1ad4629a2163",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "be79a714-f829-4f7c-a4ba-06abe7c78059",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4848ef6d457f4595\n",
      "Reusing dataset csv (/home/piai/.cache/huggingface/datasets/csv/default-4848ef6d457f4595/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d131c031c61c40b99804ff022ef1a04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c77503df04c420981e719805bb4e971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/179700 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "TEST = \"../data/test.csv\"\n",
    "SUB = \"../data/sample_submission.csv\"\n",
    "\n",
    "test_dataset = load_dataset(\"csv\", data_files=TEST)[\"train\"]\n",
    "test_dataset = test_dataset.map(example_fn, remove_columns=[\"code1\", \"code2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5884801b-1aec-4564-b38c-17ef9e23ddb3",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "66a83d02-ab2a-46ce-a3c4-d0eac701f361",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "test_size = len(test_dataset)\n",
    "predictions = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacc2cdb-57f9-4060-8703-f3744e6133c9",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "930fb62c-166d-4f95-8085-2c6107808319",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "## Setting for K-fold train and inference test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6ea16-5e21-40c2-a00c-c7f9b45ca3bc",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "72260e4c-b43e-429c-b84a-ecc3813e13db",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "1th fold - Training start\n",
      "----------------------------------------------------------------------------------------------------\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running training *****\n",
      "  Num examples = 480000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 45000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnahyeonkang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/piai/.jupyter/lab/workspaces/code_clone_detection/notebooks/wandb/run-20220607_101619-gz02tiew</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nahyeonkang/huggingface/runs/gz02tiew\" target=\"_blank\">./models/fold1</a></strong> to <a href=\"https://wandb.ai/nahyeonkang/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='45000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2000/45000 2:28:03 < 53:06:32, 0.22 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.027190</td>\n",
       "      <td>0.995108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.029157</td>\n",
       "      <td>0.994017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.033534</td>\n",
       "      <td>0.993342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.042651</td>\n",
       "      <td>0.992383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold1/checkpoint-500\n",
      "Configuration saved in ./models/fold1/checkpoint-500/config.json\n",
      "Model weights saved in ./models/fold1/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold1/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold1/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold1/checkpoint-2000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold1/checkpoint-1000\n",
      "Configuration saved in ./models/fold1/checkpoint-1000/config.json\n",
      "Model weights saved in ./models/fold1/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold1/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold1/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold1/checkpoint-3000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold1/checkpoint-1500\n",
      "Configuration saved in ./models/fold1/checkpoint-1500/config.json\n",
      "Model weights saved in ./models/fold1/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold1/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold1/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold1/checkpoint-3500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold1/checkpoint-2000\n",
      "Configuration saved in ./models/fold1/checkpoint-2000/config.json\n",
      "Model weights saved in ./models/fold1/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold1/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold1/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold1/checkpoint-4000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models/fold1/checkpoint-500 (score: 0.02718997560441494).\n",
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "1th fold - Inference start\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 38:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "2th fold - Training start\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 480000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 45000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='45000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3000/45000 3:43:16 < 52:07:51, 0.22 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.032458</td>\n",
       "      <td>0.994283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.027827</td>\n",
       "      <td>0.993883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.027394</td>\n",
       "      <td>0.994350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.039131</td>\n",
       "      <td>0.991883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>0.993550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.029672</td>\n",
       "      <td>0.994692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold2/checkpoint-500\n",
      "Configuration saved in ./models/fold2/checkpoint-500/config.json\n",
      "Model weights saved in ./models/fold2/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold2/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold2/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold2/checkpoint-4500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold2/checkpoint-1000\n",
      "Configuration saved in ./models/fold2/checkpoint-1000/config.json\n",
      "Model weights saved in ./models/fold2/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold2/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold2/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold2/checkpoint-5500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold2/checkpoint-1500\n",
      "Configuration saved in ./models/fold2/checkpoint-1500/config.json\n",
      "Model weights saved in ./models/fold2/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold2/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold2/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold2/checkpoint-6000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold2/checkpoint-2000\n",
      "Configuration saved in ./models/fold2/checkpoint-2000/config.json\n",
      "Model weights saved in ./models/fold2/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold2/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold2/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold2/checkpoint-6500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold2/checkpoint-2500\n",
      "Configuration saved in ./models/fold2/checkpoint-2500/config.json\n",
      "Model weights saved in ./models/fold2/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold2/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold2/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold2/checkpoint-7000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold2/checkpoint-3000\n",
      "Configuration saved in ./models/fold2/checkpoint-3000/config.json\n",
      "Model weights saved in ./models/fold2/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold2/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold2/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold2/checkpoint-500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models/fold2/checkpoint-1500 (score: 0.027394458651542664).\n",
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "2th fold - Inference start\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 38:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "3th fold - Training start\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 480000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 45000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='45000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3000/45000 3:42:31 < 51:57:19, 0.22 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>0.992833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.027065</td>\n",
       "      <td>0.993967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.995692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.024676</td>\n",
       "      <td>0.995150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.995258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.022549</td>\n",
       "      <td>0.994817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold3/checkpoint-500\n",
      "Configuration saved in ./models/fold3/checkpoint-500/config.json\n",
      "Model weights saved in ./models/fold3/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold3/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold3/checkpoint-500/special_tokens_map.json\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold3/checkpoint-1000\n",
      "Configuration saved in ./models/fold3/checkpoint-1000/config.json\n",
      "Model weights saved in ./models/fold3/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold3/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold3/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold3/checkpoint-1500] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold3/checkpoint-1500\n",
      "Configuration saved in ./models/fold3/checkpoint-1500/config.json\n",
      "Model weights saved in ./models/fold3/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold3/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold3/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold3/checkpoint-2000] due to args.save_total_limit\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/fold3/checkpoint-3000\n",
      "Configuration saved in ./models/fold3/checkpoint-3000/config.json\n",
      "Model weights saved in ./models/fold3/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/fold3/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./models/fold3/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [models/fold3/checkpoint-500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models/fold3/checkpoint-1500 (score: 0.015510955825448036).\n",
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "3th fold - Inference start\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 38:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "4th fold - Training start\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 480000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 45000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='45000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  501/45000 11:48 < 17:33:37, 0.70 it/s, Epoch 0.03/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='264' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 264/1875 03:33 < 21:47, 1.23 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120000\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "k_fold = 5\n",
    "gap = int(len(train_dataset) / k_fold)\n",
    "\n",
    "for fold in range(k_fold):\n",
    "    print(\"-\"*100)\n",
    "    print(f\"{fold+1}th fold - Training start\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    output_dir = './models/' + f\"fold{fold+1}\"\n",
    "    dataset_size = len(train_dataset)\n",
    "    total_ids = list(range(dataset_size))      # 전체 dataset 크기 index\n",
    "    del_ids = list(range(fold*gap, (fold+1)*gap))    # 0 ~ 120,000, 120,000 ~ 240,000 과 같이 나눠줌\n",
    "    training_ids = set(total_ids) - set(del_ids) # 0 ~ 600,000에서 del_ids를 빼면 그만큼 training fold가 됨\n",
    "    \n",
    "    fold_train_dataset = train_dataset.select(list(training_ids))\n",
    "    fold_valid_dataset = train_dataset.select(del_ids)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=32,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=250,\n",
    "        disable_tqdm = False,\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        save_strategy=\"steps\",\n",
    "        logging_strategy=\"steps\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        learning_rate=2e-5,\n",
    "        optim='adamw_torch',\n",
    "        # metric_for_best_model= \"f1\",\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            data_collator=_collator,\n",
    "            train_dataset=fold_train_dataset,\n",
    "            eval_dataset=fold_valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics= metric_fn,\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    \n",
    "    do_train()\n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    print(f\"{fold+1}th fold - Inference start\")\n",
    "    print(\"-\"*100)\n",
    "    pred = trainer.predict(test_dataset)\n",
    "    predictions.append(pred.predictions)\n",
    "    \n",
    "    label = np.argmax(pred.predictions, axis=-1)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a6cea1-c5ec-464d-bbe8-447a8436d0d4",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": "87c2338a-2405-48c6-a655-5b5cec252f4e",
     "headerColor": "inherit",
     "id": "882c38be-b1e3-4fb4-b92b-acede785f488",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/piai/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Inference start\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 37:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 38:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 38:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 38:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2808' max='2808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2808/2808 38:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = './models/' + f\"final\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=32,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=250,\n",
    "        disable_tqdm = False,\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        save_strategy=\"steps\",\n",
    "        logging_strategy=\"steps\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        learning_rate=2e-5,\n",
    "        optim='adamw_torch',\n",
    "        # metric_for_best_model= \"f1\",\n",
    "        save_total_limit=5,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            data_collator=_collator,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics= metric_fn,\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "############################\n",
    "trainer2 = Trainer(\n",
    "            model=model2,\n",
    "            args=args,\n",
    "            data_collator=_collator,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics= metric_fn,\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "#####################\n",
    "trainer3 = Trainer(\n",
    "            model=model3,\n",
    "            args=args,\n",
    "            data_collator=_collator,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics= metric_fn,\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "################\n",
    "trainer4 = Trainer(\n",
    "            model=model4,\n",
    "            args=args,\n",
    "            data_collator=_collator,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics= metric_fn,\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "############################\n",
    "trainer5 = Trainer(\n",
    "            model=model5,\n",
    "            args=args,\n",
    "            data_collator=_collator,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics= metric_fn,\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(f\"Inference start\")\n",
    "print(\"-\"*100)\n",
    "pred = trainer.predict(test_dataset)\n",
    "pred2 = trainer2.predict(test_dataset)\n",
    "pred3 = trainer3.predict(test_dataset)\n",
    "pred4 = trainer4.predict(test_dataset)\n",
    "pred5 = trainer5.predict(test_dataset)\n",
    "predictions.append(pred.predictions)\n",
    "predictions.append(pred2.predictions)\n",
    "predictions.append(pred3.predictions)\n",
    "predictions.append(pred4.predictions)\n",
    "predictions.append(pred5.predictions)\n",
    "\n",
    "label = np.argmax(pred.predictions, axis=-1)\n",
    "label2 = np.argmax(pred2.predictions, axis=-1)\n",
    "label3 = np.argmax(pred3.predictions, axis=-1)\n",
    "label4 = np.argmax(pred4.predictions, axis=-1)\n",
    "label5 = np.argmax(pred5.predictions, axis=-1)\n",
    "labels.append(label)\n",
    "labels.append(label2)\n",
    "labels.append(label3)\n",
    "labels.append(label4)\n",
    "labels.append(label5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a38af01-bffb-41de-be1a-65b5c8f60e32",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "7955b87c-8547-4b2a-8c1c-37baa781395e",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 5.27169  , -5.3973827],\n",
      "       [-5.06581  ,  5.21526  ],\n",
      "       [ 4.717493 , -4.670257 ],\n",
      "       ...,\n",
      "       [ 5.1468363, -5.170413 ],\n",
      "       [-5.061063 ,  5.208819 ],\n",
      "       [ 2.6489146, -2.2357914]], dtype=float32), array([[ 4.8886895, -4.8665314],\n",
      "       [-3.874259 ,  3.765397 ],\n",
      "       [ 2.589425 , -2.2947364],\n",
      "       ...,\n",
      "       [ 3.7384713, -3.5434034],\n",
      "       [-3.8515565,  3.749201 ],\n",
      "       [ 1.6035545, -1.3466036]], dtype=float32), array([[ 5.034718 , -5.234578 ],\n",
      "       [-4.4402866,  4.5899   ],\n",
      "       [ 4.8308353, -4.8489704],\n",
      "       ...,\n",
      "       [ 4.168168 , -4.001863 ],\n",
      "       [-4.5176706,  4.670958 ],\n",
      "       [-1.4308709,  1.6540235]], dtype=float32), array([[ 5.3510113, -5.5393786],\n",
      "       [-5.1544895,  5.301077 ],\n",
      "       [ 5.1196322, -5.1616297],\n",
      "       ...,\n",
      "       [ 5.2493987, -5.3089194],\n",
      "       [-5.161056 ,  5.309693 ],\n",
      "       [ 4.140885 , -3.833423 ]], dtype=float32), array([[ 5.215371 , -5.473607 ],\n",
      "       [-5.0005484,  5.215244 ],\n",
      "       [ 5.040931 , -5.1367474],\n",
      "       ...,\n",
      "       [ 4.793576 , -4.8029656],\n",
      "       [-4.9748955,  5.1995244],\n",
      "       [ 2.531952 , -2.2177498]], dtype=float32)]\n",
      "[array([0, 1, 0, ..., 0, 1, 0]), array([0, 1, 0, ..., 0, 1, 0]), array([0, 1, 0, ..., 0, 1, 1]), array([0, 1, 0, ..., 0, 1, 0]), array([0, 1, 0, ..., 0, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94d99c-efa3-4aec-acef-2af707370312",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "8c80b9e4-adf3-4eeb-ad0e-ec5c507ca3c5",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "### Inference test dataset by using Hard and Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea1a37c-0754-48b7-8e84-f6ade67349ae",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "2a2036ed-4210-4d85-9e06-517c56054e14",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# Hard voting\n",
    "hard_voted_labels = []\n",
    "for i in range(test_size):\n",
    "    label_list = [label[i] for label in labels]\n",
    "    counter = Counter(label_list)\n",
    "    selected = sorted(counter.items(), key=lambda x : x[1], reverse=True)[0][0]\n",
    "    hard_voted_labels.append(selected)\n",
    "    \n",
    "hard_voted_df = pd.read_csv(SUB)\n",
    "hard_voted_df['similar'] = hard_voted_labels\n",
    "hard_voted_df.to_csv(\"./submissions/final_submission_HardVoting.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0944bd9a-cace-4284-b75c-c41e874fcd23",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "inherit",
     "id": "fe759983-c313-4d26-b2e9-7a30a9d9fefd",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# Softmax voting\n",
    "probs = np.sum(predictions, axis=0)/5\n",
    "soft_voted_labels = np.argmax(probs, axis=-1)\n",
    "\n",
    "soft_voted_df = pd.read_csv(SUB)\n",
    "soft_voted_df['similar'] = soft_voted_labels\n",
    "soft_voted_df.to_csv(\"./submissions/final_submission_SoftVoting.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
